{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#import mayavi.mlab as mlab\n",
    "import sys\n",
    "sys.path.append('/home/sbreuers/vathos/s4g-release/inference/')\n",
    "from grasp_proposal.utils.grasp_visualizer import GraspVisualizer\n",
    "import open3d\n",
    "from grasp_proposal.cloud_processor.cloud_processor import CloudPreProcessor\n",
    "import torch\n",
    "import pickle\n",
    "\n",
    "#from grasp_proposal.grasp_proposal_test import load_static_data_batch\n",
    "def load_static_data_batch():\n",
    "    #single_training_data = np.load(\"inference/2638_view_0.p\", allow_pickle=True)\n",
    "    single_training_data = np.load(\"inference/last_pointcloud_big.p\", allow_pickle=True)\n",
    "    cloud_array = single_training_data[\"point_cloud\"]\n",
    "    cloud = CloudPreProcessor(open3d.geometry.PointCloud(open3d.utility.Vector3dVector(cloud_array.T)), False)\n",
    "\n",
    "    # do not filter workspace here since training data\n",
    "    cloud.voxelize()\n",
    "    cloud.remove_outliers()\n",
    "    points = np.asarray(cloud.pcd.points)\n",
    "    if points.shape[0] > 25600:\n",
    "        random_index = np.random.choice(np.arange(points.shape[0]), 25600, replace=False)\n",
    "    else:\n",
    "        random_index = np.random.choice(np.arange(points.shape[0]), 25600, replace=True)\n",
    "\n",
    "    points = points[random_index, :]\n",
    "    data_batch = {\"scene_points\": torch.tensor(points, dtype=torch.float32).unsqueeze(0).transpose(1, 2)}\n",
    "    return data_batch, cloud.pcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # visualize result\n",
    "data_batch, pcd = load_static_data_batch()\n",
    "top_poses = np.load(\"inference/grasp_proposal/top_frames.npy\")\n",
    "visualizer = GraspVisualizer(pcd)\n",
    "visualizer.add_multiple_poses(top_poses)\n",
    "visualizer.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['search_score', 'antipodal_score', 'valid_frame', 'valid_index', 'point_cloud', 'objects_label'])\n",
      "point cloud\n",
      "(3, 48902)\n",
      "[[ 0.23269033  0.22019997  0.22615957  0.19583142  0.1853585 ]\n",
      " [ 0.34287396  0.3386026   0.33791447  0.34177426  0.34445158]\n",
      " [-1.014849   -1.0107541  -1.0115755  -1.0424486  -1.0506148 ]]\n",
      "search score\n",
      "(306,)\n",
      "[456.6667  387.66666 316.      294.      462.     ]\n",
      "antipodal_score\n",
      "(306,)\n",
      "[0.97540945 0.97183985 0.98422176 0.97475517 0.9976949 ]\n",
      "valid_frame\n",
      "(306, 4, 4)\n",
      "[[-0.21604782 -0.19880381  0.95592916 -0.24223596]\n",
      " [-0.8274021   0.55708593 -0.07114293  0.2534126 ]\n",
      " [-0.5183912  -0.80630785 -0.28484792 -1.2580454 ]\n",
      " [ 0.          0.          0.          1.        ]]\n",
      "valid_index\n",
      "(306,)\n",
      "[2389 2928 3564 3687 3688]\n",
      "objects_label\n",
      "(306,)\n",
      "[105 105  70  70  70]\n"
     ]
    }
   ],
   "source": [
    "# inspect their pointcloud\n",
    "single_training_data = np.load(\"inference/2638_view_0.p\", allow_pickle=True)\n",
    "print(single_training_data.keys())\n",
    "print(\"point cloud\")\n",
    "print(single_training_data[\"point_cloud\"].shape)\n",
    "print(single_training_data[\"point_cloud\"][:,0:5])\n",
    "print(\"search score\")\n",
    "print(single_training_data[\"search_score\"].shape)\n",
    "print(single_training_data[\"search_score\"][0:5])\n",
    "print(\"antipodal_score\")\n",
    "print(single_training_data[\"antipodal_score\"].shape)\n",
    "print(single_training_data[\"antipodal_score\"][0:5])\n",
    "print(\"valid_frame\")\n",
    "print(single_training_data[\"valid_frame\"].shape)\n",
    "print(single_training_data[\"valid_frame\"][0,:,:])\n",
    "print(\"valid_index\")\n",
    "print(single_training_data[\"valid_index\"].shape)\n",
    "print(single_training_data[\"valid_index\"][0:5])\n",
    "print(\"objects_label\")\n",
    "print(single_training_data[\"objects_label\"].shape)\n",
    "print(single_training_data[\"objects_label\"][0:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 217088)\n"
     ]
    }
   ],
   "source": [
    "# save our pointcloud\n",
    "our_pointcloud = np.load(\"/home/sbreuers/data/images/last_pointcloud_big.npy\").T\n",
    "our_pointcloud[0,:] *=  -1\n",
    "our_pointcloud[2,:] *=  -1\n",
    "i = our_pointcloud[0,:].copy()\n",
    "our_pointcloud[0,:] = our_pointcloud[1,:].copy()\n",
    "our_pointcloud[1,:] = i\n",
    "print(our_pointcloud.shape)\n",
    "pointcloud_dict = {}\n",
    "pointcloud_dict[\"point_cloud\"] = our_pointcloud\n",
    "output_path = \"inference/last_pointcloud_big.p\"\n",
    "with open(output_path, 'wb') as file:\n",
    "    pickle.dump(pointcloud_dict, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['point_cloud'])\n",
      "(3, 217088)\n",
      "[[-0.47898031 -0.47906378 -0.47914478 -0.47922591 -0.47930944]\n",
      " [ 0.61004786  0.60781444  0.60557707  0.60333909  0.6011033 ]\n",
      " [-0.8605808  -0.86073077 -0.86087632 -0.86102206 -0.86117214]]\n"
     ]
    }
   ],
   "source": [
    "# inspect our pointcloud\n",
    "single_training_data = np.load(\"inference/last_pointcloud_10.p\", allow_pickle=True)\n",
    "print(single_training_data.keys())\n",
    "print(single_training_data[\"point_cloud\"].shape)\n",
    "print(single_training_data[\"point_cloud\"][:,0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_cloud = open3d.io.read_point_cloud(\"inference/grasp_proposal/output/test_step00000/pred_pts.ply\")\n",
    "open3d.visualization.draw_geometries([point_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_797238/3562786532.py:11: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed two minor releases later. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap(obj)`` instead.\n",
      "  color_map = cm.get_cmap('jet', 256)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lager has 72 frames\n"
     ]
    }
   ],
   "source": [
    "# visualize grasps\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import open3d\n",
    "from matplotlib import cm\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/sbreuers/vathos/s4g-release/data_gen/')\n",
    "\n",
    "color_map = cm.get_cmap('jet', 256)\n",
    "data_dir = \"/home/sbreuers/vathos/s4g-release/objects/processed_single_object_grasp\" \n",
    "object_names = [\"Lager\"]\n",
    "for object_name in object_names:\n",
    "    data_path = os.path.join(data_dir, '{}.pkl'.format(object_name))\n",
    "\n",
    "    data = np.load(data_path, allow_pickle=True)\n",
    "    cloud = data['cloud']\n",
    "    grasp_pose = data['grasp_pose']\n",
    "    grasp_point_index = data['grasp_point_index'].astype(int)\n",
    "    grasp_point_index = grasp_point_index.tolist()\n",
    "    print(\"{} has {} frames\".format(object_name, len(grasp_point_index)))\n",
    "\n",
    "    pc = open3d.geometry.PointCloud()\n",
    "    pc.points = open3d.utility.Vector3dVector(cloud)\n",
    "\n",
    "    score = np.zeros([cloud.shape[0]])\n",
    "    color = np.zeros([cloud.shape[0], 3])\n",
    "\n",
    "    for i in grasp_point_index:\n",
    "        score[i] = 0.99\n",
    "\n",
    "    for i in range(cloud.shape[0]):\n",
    "        color[i, :] = color_map(score[i])[0:3]\n",
    "\n",
    "    pc.colors = open3d.utility.Vector3dVector(color)\n",
    "\n",
    "    #while True:\n",
    "    from utils.visualization_utils import get_hand_geometry\n",
    "    #vis = open3d.visualization.VisualizerWithEditing()\n",
    "    #vis.create_window()\n",
    "    #vis.add_geometry(pc)\n",
    "    #vis.run()\n",
    "    #vis.destroy_window()\n",
    "    #pick_inds = vis.get_picked_points()\n",
    "    vis_list = [pc]\n",
    "    for ind in grasp_point_index: #pick_inds:\n",
    "        if ind in grasp_point_index:\n",
    "            frame_index = grasp_point_index.index(ind)\n",
    "            grasp = np.linalg.inv(grasp_pose[frame_index])\n",
    "            #print(grasp_pose[frame_index])\n",
    "            hand = get_hand_geometry(grasp)\n",
    "            ball = open3d.geometry.TriangleMesh.create_sphere(0.0015)\n",
    "            ball.translate(cloud[ind, :])\n",
    "            vis_list.extend(hand)\n",
    "            vis_list.append(ball)\n",
    "            #break\n",
    "    open3d.visualization.draw_geometries(vis_list)\n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['grasp_pose', 'grasp_point_index', 'cloud', 'normal'])\n",
      "(587, 3)\n"
     ]
    }
   ],
   "source": [
    "print(data.keys())\n",
    "print(data['normal'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy data\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "POINT_CLOUD_SIZE = 5000\n",
    "NUM_OBJECTS = 10\n",
    "\n",
    "# Example data dictionary (replace with your actual data)\n",
    "data_dict = {\n",
    "    \"point_cloud\": np.random.rand(3, POINT_CLOUD_SIZE),  # 3D points\n",
    "    \"search_score\": np.random.rand(NUM_OBJECTS,),\n",
    "    \"antipodal_score\": np.random.rand(NUM_OBJECTS, ),\n",
    "    \"valid_frame\": np.random.rand(NUM_OBJECTS, 4, 4),  # Transformation matrices\n",
    "    \"valid_index\": np.random.choice(POINT_CLOUD_SIZE, size=NUM_OBJECTS, replace=False).astype(int),\n",
    "    \"direction\": np.random.rand(NUM_OBJECTS, 5),\n",
    "    \"objects_label\": np.zeros((NUM_OBJECTS,)).astype(int),\n",
    "}\n",
    "\n",
    "# Save to pickle file\n",
    "output_file = \"/home/sbreuers/vathos/s4g-release/tdgpd/datasets/bearring/val/scene_001.p\"\n",
    "with open(output_file, \"wb\") as f:\n",
    "    pickle.dump(data_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_keys(['search_score', 'antipodal_score', 'valid_frame', 'valid_index', 'point_cloud', 'objects_label'])\n",
    "\n",
    "#point cloud\n",
    "#(3, 48902)\n",
    "#[[ 0.23269033  0.22019997  0.22615957  0.19583142  0.1853585 ]\n",
    "# [ 0.34287396  0.3386026   0.33791447  0.34177426  0.34445158]\n",
    "# [-1.014849   -1.0107541  -1.0115755  -1.0424486  -1.0506148 ]]\n",
    "\n",
    "#search score\n",
    "#(306,)\n",
    "#[456.6667  387.66666 316.      294.      462.     ]\n",
    "\n",
    "#antipodal_score\n",
    "#(306,)\n",
    "#[0.97540945 0.97183985 0.98422176 0.97475517 0.9976949 ]\n",
    "\n",
    "#valid_frame\n",
    "#(306, 4, 4)\n",
    "#[[-0.21604782 -0.19880381  0.95592916 -0.24223596]\n",
    "# [-0.8274021   0.55708593 -0.07114293  0.2534126 ]\n",
    "# [-0.5183912  -0.80630785 -0.28484792 -1.2580454 ]\n",
    "# [ 0.          0.          0.          1.        ]]\n",
    "\n",
    "#valid_index\n",
    "#(306,)\n",
    "#[2389 2928 3564 3687 3688]\n",
    "\n",
    "#objects_label\n",
    "#(306,)\n",
    "#[105 105  70  70  70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 1, 3, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.choice(5, size=5, replace=False).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
